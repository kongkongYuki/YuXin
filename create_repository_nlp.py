"""
-*- coding: utf-8 -*-
@File  : create_repository_nlp.py
@Author: Yuki
@Date  : 13/06/2022
@Software : PyCharm
"""

import os
import json
import csv
import docx
import spacy
from blackstone.pipeline import CompoundCases, SentenceSegmenter
from blackstone.rules import CITATION_PATTERNS


def get_top_cat(doc):
    """
    Function to identify the highest scoring category
    prediction generated by the text categoriser.
    """
    cats = doc.cats
    max_score = max(cats.values())
    max_cats = [k for k, v in cats.items() if v == max_score]
    max_cat = max_cats[0]
    return max_cat, max_score


def get_results(text, citation):
    nlp = spacy.load("en_blackstone_proto")
    compound_pipe = CompoundCases(nlp)
    doc = nlp(text)
    sentence_segmenter = SentenceSegmenter(nlp.vocab, CITATION_PATTERNS)
    nlp.add_pipe(sentence_segmenter, before="parser")
    sentences = [sent.text for sent in doc.sents]
    # Iterate through the entities identified by the model
    results = {
        'CITATION': [],
        'INSTRUMENT': []
    }
    for ent in doc.ents:
        if ent.label_ in results.keys():
            if ent.text not in results[ent.label_]:
                tmp = str(ent.text).replace("[", "").replace("]", "").replace(" ", "_")
                if ent.label_ == 'CITATION' and tmp == citation:
                    continue
                results[ent.label_].append(ent.text.strip().replace("\n", " "))
    return results


def getText(filename):
    doc = docx.Document(filename)
    fullText = []
    for para in doc.paragraphs:
        fullText.append(para.text)
    return '\n'.join(fullText)


def nlp_metadata(inpath, outpath):
    files = os.listdir(inpath)
    result_file = []
    for file in files:
        if not file.startswith('.') and not os.path.isdir(file):
            citation = file.split('.')[0]
            final_results = get_results(getText(inpath + "/" + file), citation)
            final_results['Neutral Citation'] = citation
            result_file.append(final_results)
            print(citation)
    print('Done')

    json_object = json.dumps(result_file, indent=4, default=str, ensure_ascii=False)
    loaded_r = json.loads(json_object)

    if os.path.exists(outpath):
        os.remove(outpath)
    data_file = open(outpath, 'w', newline='')
    csv_writer = csv.writer(data_file)
    count = 0
    for data in loaded_r:
        if count == 0:
            header = data.keys()
            csv_writer.writerow(header)
            count += 1
        csv_writer.writerow(data.values())
    data_file.close()
    return
